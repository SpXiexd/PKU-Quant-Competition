# PKU-Quant-Competition
# 该项目是用于北京大学量化金融智能算法比赛的复赛
# 该项目还存在诸多不足，请见谅
说明文档
硬件：GPU（NVIDIA GeForce RTX 4060 Laptop GPU）、CPU（AMD Ryzen 7 7735H with Radeon Graphics   3.20 GHz）、内存（16.0 GB）。
程序文件：Lstm2.py(网络模型）、dataprocess.py(数据处理)、testDataProcess.py(测试数据处理)、testDataPre.py(测试数据预测)
1.	数据处理
所使用到的库为numpy、alive_progress和time。数据分为以下三步：
1.1 数据分类汇总。从文件traindata_original.npz中读取原始数据，按照股票代号和日期进行索引将输入数据汇总到一个numpy数组，维度一到三分别为时间、特征和股票代码（1769x56x4116），输出数据的汇总同理，维度维度一到三分别为时间、标签和股票代码（1769x56x4116）。
1.2 数据处理。所有数据的nan值均用0替换，再针对每个特征或标签进行标准化。
1.3 数据集分割。因为模型采用LSTM，同时避免整个数据集一起训练导致内存不足，需要对数据集进行。定义函数stack_arrays：该函数用于将输入的特征和标签数据进行滑动窗口处理，生成新的特征和标签数据。其中，input_array表示输入的特征数据，output_array表示输入的标签数据，time_step表示滑动窗口的大小，即是根据长为时间步长time_step的时间序列(例如1到5)，该时间序列有56个特征，预测下一个时刻（例如6）的两个标签（y_001和y_002）。将数据根据股票代号分为5份，其中4份（每份825支股票）作为训练数据集，1份（每份816支股票）作为测试数据集。通过stack_arrays函数将数据集按照所设定的时间步长time_step进行滑动窗口分割。
2.	模型设计
所使用到的库为numpy、alive_progress和time
2.1模型结构：
使用了一个具有以下参数的LSTM网络：
输入大小（input_size）：56
隐藏层大小（hidden_size）：512
输出大小（output_size）：2
层数（num_layers）：4
dropout：0
初始化LSTM层的权重使用均匀分布，并对线性层采用Xavier正态分布进行初始化。LSTM的输出将传递给一个全连接层，以生成最终的预测结果。
2.2	模型训练与测试：
在训练过程中，将数据集分成四个子集，并分别对每个子集进行训练与验证。使用均方误差损失（MSE）作为损失函数，并采用AdamW优化器优化模型的权重。
采用了自动混合精度（AMP）技术，以加快训练速度。此外，使用CyclicLR调度器设置震荡学习率，以提高模型的泛化能力。
在每个训练周期（Epoch）结束时，计算训练集和验证集上的损失，并计算斯皮尔曼秩相关系数，以评估模型在预测股票走势上的性能。在训练完成后，将模型应用到测试数据集，并计算预测结果与真实标签之间的斯皮尔曼秩相关系数平均值，以评估模型的预测能力。
3.	结果分析
经过对时间步长、学习率、优化器、隐含层数、LSTM层数等超参数的优化，发现时间步长和隐含层数对测试集的斯皮尔曼秩相关系数平均值提升最明显，但由于硬件限制，时间步长仅测试10以下。最终得到的网络，训练集的MSE可以降到0.15，验证集MSE可以降到0.25，验证集的斯皮尔曼秩相关系数平均值上升到0.7，测试集的斯皮尔曼秩相关系数平均值上升到0.4934，接近0.5。因此，认为在该硬件设备条件下，仅使用LSTM网络对y_001和y_002的预测性能已经达到较好水平。
 

